{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db713e0",
   "metadata": {},
   "source": [
    "- iris 데이터 종 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92febd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:28:02.855155Z",
     "start_time": "2024-12-19T07:27:58.421375Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns # iris 데이터\n",
    "import pandas as pd #원핫 인코딩\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495df000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:37:29.917095Z",
     "start_time": "2024-12-19T07:37:29.897149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120, 3), (30, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 생성 및 전처리\n",
    "iris = sns.load_dataset('iris')\n",
    "# 독립변수와 종속변수 분리\n",
    "iris_X = iris.iloc[:, :-1].to_numpy()\n",
    "iris_y = iris.iloc[:, -1]\n",
    "iris_Y = pd.get_dummies(iris_y).values\n",
    "# iris_Y[::50]\n",
    "# 훈련셋 : 테스트셋 = 8:2\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(iris_X, iris_Y, test_size=.2,\n",
    "                                                   stratify=iris_Y, random_state=4)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24b990e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:37:30.288368Z",
     "start_time": "2024-12-19T07:37:30.281408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40\n",
       "1    40\n",
       "2    40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 층화 추출했는지 확인\n",
    "pd.Series(np.argmax(Y_train, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc21bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:37:30.614153Z",
     "start_time": "2024-12-19T07:37:30.608155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10\n",
       "2    10\n",
       "0    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.argmax(Y_test, axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228ab68e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:37:31.674519Z",
     "start_time": "2024-12-19T07:37:30.927974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 60)                300       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                3050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,973\n",
      "Trainable params: 4,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2, 모델 구성 (입력4 - 출력3)\n",
    "model = Sequential()\n",
    "model.add(Dense(units=60, input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=30, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ab9584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:30:32.676583Z",
     "start_time": "2024-12-19T08:30:32.587858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 64)                320       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,347\n",
      "Trainable params: 13,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(4,),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16b4f37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:30:32.976642Z",
     "start_time": "2024-12-19T08:30:32.965120Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. 모델학습과정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c8ce924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:31:01.392519Z",
     "start_time": "2024-12-19T08:30:33.349094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0499 - accuracy: 0.3750\n",
      "Epoch 1: val_loss improved from inf to 1.05574, saving model to ./model\\iris-001-val0.4167.h5\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 1.1654 - accuracy: 0.3021 - val_loss: 1.0557 - val_accuracy: 0.4167\n",
      "Epoch 2/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0537 - accuracy: 0.3438\n",
      "Epoch 2: val_loss improved from 1.05574 to 1.01092, saving model to ./model\\iris-002-val0.4167.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0668 - accuracy: 0.3438 - val_loss: 1.0109 - val_accuracy: 0.4167\n",
      "Epoch 3/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0544 - accuracy: 0.3438\n",
      "Epoch 3: val_loss improved from 1.01092 to 0.98409, saving model to ./model\\iris-003-val0.4167.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0292 - accuracy: 0.3542 - val_loss: 0.9841 - val_accuracy: 0.4167\n",
      "Epoch 4/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9988 - accuracy: 0.3750\n",
      "Epoch 4: val_loss improved from 0.98409 to 0.95568, saving model to ./model\\iris-004-val0.6250.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0060 - accuracy: 0.3646 - val_loss: 0.9557 - val_accuracy: 0.6250\n",
      "Epoch 5/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9409 - accuracy: 0.3750\n",
      "Epoch 5: val_loss improved from 0.95568 to 0.90712, saving model to ./model\\iris-005-val0.5417.h5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.9551 - accuracy: 0.3542 - val_loss: 0.9071 - val_accuracy: 0.5417\n",
      "Epoch 6/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9199 - accuracy: 0.4688\n",
      "Epoch 6: val_loss improved from 0.90712 to 0.87020, saving model to ./model\\iris-006-val0.4583.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9354 - accuracy: 0.4271 - val_loss: 0.8702 - val_accuracy: 0.4583\n",
      "Epoch 7/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8852 - accuracy: 0.4688\n",
      "Epoch 7: val_loss improved from 0.87020 to 0.82957, saving model to ./model\\iris-007-val0.6250.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8973 - accuracy: 0.4479 - val_loss: 0.8296 - val_accuracy: 0.6250\n",
      "Epoch 8/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8855 - accuracy: 0.5312\n",
      "Epoch 8: val_loss improved from 0.82957 to 0.81660, saving model to ./model\\iris-008-val0.7500.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8701 - accuracy: 0.4688 - val_loss: 0.8166 - val_accuracy: 0.7500\n",
      "Epoch 9/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8176 - accuracy: 0.5312\n",
      "Epoch 9: val_loss improved from 0.81660 to 0.80092, saving model to ./model\\iris-009-val0.7917.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8395 - accuracy: 0.6146 - val_loss: 0.8009 - val_accuracy: 0.7917\n",
      "Epoch 10/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8489 - accuracy: 0.5938\n",
      "Epoch 10: val_loss improved from 0.80092 to 0.77721, saving model to ./model\\iris-010-val0.8750.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.8528 - accuracy: 0.6250 - val_loss: 0.7772 - val_accuracy: 0.8750\n",
      "Epoch 11/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9368 - accuracy: 0.6250\n",
      "Epoch 11: val_loss improved from 0.77721 to 0.76152, saving model to ./model\\iris-011-val0.8750.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8356 - accuracy: 0.6562 - val_loss: 0.7615 - val_accuracy: 0.8750\n",
      "Epoch 12/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8217 - accuracy: 0.7188\n",
      "Epoch 12: val_loss improved from 0.76152 to 0.74677, saving model to ./model\\iris-012-val0.9167.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8680 - accuracy: 0.6458 - val_loss: 0.7468 - val_accuracy: 0.9167\n",
      "Epoch 13/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8717 - accuracy: 0.7188\n",
      "Epoch 13: val_loss improved from 0.74677 to 0.73600, saving model to ./model\\iris-013-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8254 - accuracy: 0.7708 - val_loss: 0.7360 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7679 - accuracy: 0.9062\n",
      "Epoch 14: val_loss improved from 0.73600 to 0.71818, saving model to ./model\\iris-014-val1.0000.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.8078 - accuracy: 0.7708 - val_loss: 0.7182 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8489 - accuracy: 0.7188\n",
      "Epoch 15: val_loss improved from 0.71818 to 0.70880, saving model to ./model\\iris-015-val1.0000.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8173 - accuracy: 0.7500 - val_loss: 0.7088 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.9215 - accuracy: 0.6875\n",
      "Epoch 16: val_loss improved from 0.70880 to 0.69424, saving model to ./model\\iris-016-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8337 - accuracy: 0.7500 - val_loss: 0.6942 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7709 - accuracy: 0.8125\n",
      "Epoch 17: val_loss improved from 0.69424 to 0.67096, saving model to ./model\\iris-017-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7323 - accuracy: 0.8750 - val_loss: 0.6710 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7272 - accuracy: 0.8125\n",
      "Epoch 18: val_loss improved from 0.67096 to 0.65358, saving model to ./model\\iris-018-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7668 - accuracy: 0.7708 - val_loss: 0.6536 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6552 - accuracy: 0.9375\n",
      "Epoch 19: val_loss improved from 0.65358 to 0.63352, saving model to ./model\\iris-019-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7108 - accuracy: 0.8646 - val_loss: 0.6335 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7266 - accuracy: 0.8125\n",
      "Epoch 20: val_loss improved from 0.63352 to 0.61145, saving model to ./model\\iris-020-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6997 - accuracy: 0.8229 - val_loss: 0.6114 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7590 - accuracy: 0.9375\n",
      "Epoch 21: val_loss did not improve from 0.61145\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7108 - accuracy: 0.8229 - val_loss: 0.6184 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6764 - accuracy: 0.8750\n",
      "Epoch 22: val_loss did not improve from 0.61145\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7213 - accuracy: 0.8958 - val_loss: 0.6176 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6658 - accuracy: 0.8750\n",
      "Epoch 23: val_loss improved from 0.61145 to 0.59377, saving model to ./model\\iris-023-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6693 - accuracy: 0.9062 - val_loss: 0.5938 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6085 - accuracy: 0.7500\n",
      "Epoch 24: val_loss improved from 0.59377 to 0.54841, saving model to ./model\\iris-024-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6817 - accuracy: 0.8125 - val_loss: 0.5484 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7077 - accuracy: 0.8750\n",
      "Epoch 25: val_loss improved from 0.54841 to 0.53468, saving model to ./model\\iris-025-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6566 - accuracy: 0.8438 - val_loss: 0.5347 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8307 - accuracy: 0.8438\n",
      "Epoch 26: val_loss improved from 0.53468 to 0.53365, saving model to ./model\\iris-026-val1.0000.h5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6578 - accuracy: 0.8958 - val_loss: 0.5336 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6474 - accuracy: 0.9062\n",
      "Epoch 27: val_loss improved from 0.53365 to 0.52630, saving model to ./model\\iris-027-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6064 - accuracy: 0.9062 - val_loss: 0.5263 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5620 - accuracy: 0.8750\n",
      "Epoch 28: val_loss improved from 0.52630 to 0.50981, saving model to ./model\\iris-028-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5919 - accuracy: 0.8958 - val_loss: 0.5098 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5924 - accuracy: 0.8750\n",
      "Epoch 29: val_loss improved from 0.50981 to 0.49982, saving model to ./model\\iris-029-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6204 - accuracy: 0.8854 - val_loss: 0.4998 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6218 - accuracy: 0.8750\n",
      "Epoch 30: val_loss improved from 0.49982 to 0.49573, saving model to ./model\\iris-030-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5862 - accuracy: 0.9062 - val_loss: 0.4957 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5586 - accuracy: 0.9375\n",
      "Epoch 31: val_loss improved from 0.49573 to 0.46790, saving model to ./model\\iris-031-val1.0000.h5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5652 - accuracy: 0.9375 - val_loss: 0.4679 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7125 - accuracy: 0.9375\n",
      "Epoch 32: val_loss did not improve from 0.46790\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6355 - accuracy: 0.9271 - val_loss: 0.4913 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5306 - accuracy: 0.9375\n",
      "Epoch 33: val_loss improved from 0.46790 to 0.45009, saving model to ./model\\iris-033-val1.0000.h5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5806 - accuracy: 0.9062 - val_loss: 0.4501 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5614 - accuracy: 0.9062\n",
      "Epoch 34: val_loss improved from 0.45009 to 0.44724, saving model to ./model\\iris-034-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5678 - accuracy: 0.8958 - val_loss: 0.4472 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4510 - accuracy: 0.9688\n",
      "Epoch 35: val_loss improved from 0.44724 to 0.44197, saving model to ./model\\iris-035-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5260 - accuracy: 0.9375 - val_loss: 0.4420 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5698 - accuracy: 0.8750\n",
      "Epoch 36: val_loss improved from 0.44197 to 0.42260, saving model to ./model\\iris-036-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5601 - accuracy: 0.8958 - val_loss: 0.4226 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4695 - accuracy: 0.9062\n",
      "Epoch 37: val_loss did not improve from 0.42260\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5995 - accuracy: 0.8854 - val_loss: 0.4600 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5143 - accuracy: 0.9062\n",
      "Epoch 38: val_loss did not improve from 0.42260\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6014 - accuracy: 0.8854 - val_loss: 0.5115 - val_accuracy: 0.9583\n",
      "Epoch 39/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5836 - accuracy: 0.8750\n",
      "Epoch 39: val_loss improved from 0.42260 to 0.40658, saving model to ./model\\iris-039-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5433 - accuracy: 0.8958 - val_loss: 0.4066 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4507 - accuracy: 0.9688\n",
      "Epoch 40: val_loss improved from 0.40658 to 0.40303, saving model to ./model\\iris-040-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5506 - accuracy: 0.8958 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5066 - accuracy: 0.9688\n",
      "Epoch 41: val_loss did not improve from 0.40303\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5054 - accuracy: 0.9375 - val_loss: 0.4426 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5819 - accuracy: 0.9375\n",
      "Epoch 42: val_loss did not improve from 0.40303\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5562 - accuracy: 0.9271 - val_loss: 0.4804 - val_accuracy: 0.9583\n",
      "Epoch 43/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5615 - accuracy: 0.9062\n",
      "Epoch 43: val_loss improved from 0.40303 to 0.38872, saving model to ./model\\iris-043-val1.0000.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5227 - accuracy: 0.9479 - val_loss: 0.3887 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5412 - accuracy: 0.8438\n",
      "Epoch 44: val_loss improved from 0.38872 to 0.38242, saving model to ./model\\iris-044-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5658 - accuracy: 0.8646 - val_loss: 0.3824 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4338 - accuracy: 0.9375\n",
      "Epoch 45: val_loss did not improve from 0.38242\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4905 - accuracy: 0.9375 - val_loss: 0.3852 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4078 - accuracy: 0.9375\n",
      "Epoch 46: val_loss did not improve from 0.38242\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5840 - accuracy: 0.8542 - val_loss: 0.4116 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4746 - accuracy: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.38242\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5096 - accuracy: 0.9375 - val_loss: 0.4129 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5242 - accuracy: 0.9375\n",
      "Epoch 48: val_loss did not improve from 0.38242\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4974 - accuracy: 0.9479 - val_loss: 0.3853 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5601 - accuracy: 0.9062\n",
      "Epoch 49: val_loss did not improve from 0.38242\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5389 - accuracy: 0.8958 - val_loss: 0.3953 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5077 - accuracy: 0.8750\n",
      "Epoch 50: val_loss improved from 0.38242 to 0.37203, saving model to ./model\\iris-050-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4532 - accuracy: 0.9375 - val_loss: 0.3720 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4135 - accuracy: 0.9062\n",
      "Epoch 51: val_loss improved from 0.37203 to 0.36262, saving model to ./model\\iris-051-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4911 - accuracy: 0.9375 - val_loss: 0.3626 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4110 - accuracy: 0.9688\n",
      "Epoch 52: val_loss did not improve from 0.36262\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4919 - accuracy: 0.9271 - val_loss: 0.3719 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5755 - accuracy: 0.9375\n",
      "Epoch 53: val_loss did not improve from 0.36262\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4967 - accuracy: 0.9479 - val_loss: 0.4107 - val_accuracy: 0.9583\n",
      "Epoch 54/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5658 - accuracy: 0.9375\n",
      "Epoch 54: val_loss did not improve from 0.36262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5263 - accuracy: 0.9062 - val_loss: 0.3726 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6476 - accuracy: 0.8750\n",
      "Epoch 55: val_loss improved from 0.36262 to 0.35159, saving model to ./model\\iris-055-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4698 - accuracy: 0.9479 - val_loss: 0.3516 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5168 - accuracy: 0.9375\n",
      "Epoch 56: val_loss did not improve from 0.35159\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4754 - accuracy: 0.9375 - val_loss: 0.3592 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5553 - accuracy: 0.9375\n",
      "Epoch 57: val_loss did not improve from 0.35159\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5042 - accuracy: 0.9271 - val_loss: 0.3954 - val_accuracy: 0.9583\n",
      "Epoch 58/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4707 - accuracy: 0.8750\n",
      "Epoch 58: val_loss did not improve from 0.35159\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4567 - accuracy: 0.9271 - val_loss: 0.3632 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6524 - accuracy: 0.8750\n",
      "Epoch 59: val_loss improved from 0.35159 to 0.34219, saving model to ./model\\iris-059-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4731 - accuracy: 0.9271 - val_loss: 0.3422 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4202 - accuracy: 0.9688\n",
      "Epoch 60: val_loss improved from 0.34219 to 0.33907, saving model to ./model\\iris-060-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4333 - accuracy: 0.9479 - val_loss: 0.3391 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5943 - accuracy: 0.9062\n",
      "Epoch 61: val_loss did not improve from 0.33907\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5445 - accuracy: 0.9271 - val_loss: 0.3501 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4543 - accuracy: 0.9688\n",
      "Epoch 62: val_loss did not improve from 0.33907\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4791 - accuracy: 0.9375 - val_loss: 0.3700 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3590 - accuracy: 0.9375\n",
      "Epoch 63: val_loss did not improve from 0.33907\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4416 - accuracy: 0.9479 - val_loss: 0.3552 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5270 - accuracy: 0.9688\n",
      "Epoch 64: val_loss improved from 0.33907 to 0.33625, saving model to ./model\\iris-064-val1.0000.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4277 - accuracy: 0.9688 - val_loss: 0.3362 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3899 - accuracy: 0.9688\n",
      "Epoch 65: val_loss improved from 0.33625 to 0.33308, saving model to ./model\\iris-065-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4073 - accuracy: 0.9688 - val_loss: 0.3331 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3826 - accuracy: 0.9688\n",
      "Epoch 66: val_loss did not improve from 0.33308\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4582 - accuracy: 0.9688 - val_loss: 0.3373 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4525 - accuracy: 0.9688\n",
      "Epoch 67: val_loss improved from 0.33308 to 0.33173, saving model to ./model\\iris-067-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4561 - accuracy: 0.9583 - val_loss: 0.3317 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4865 - accuracy: 0.9375\n",
      "Epoch 68: val_loss improved from 0.33173 to 0.32197, saving model to ./model\\iris-068-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4343 - accuracy: 0.9375 - val_loss: 0.3220 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5658 - accuracy: 0.9375\n",
      "Epoch 69: val_loss did not improve from 0.32197\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4484 - accuracy: 0.9479 - val_loss: 0.3650 - val_accuracy: 0.9583\n",
      "Epoch 70/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4946 - accuracy: 0.9688\n",
      "Epoch 70: val_loss did not improve from 0.32197\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4759 - accuracy: 0.9167 - val_loss: 0.3429 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4701 - accuracy: 0.9375\n",
      "Epoch 71: val_loss improved from 0.32197 to 0.31545, saving model to ./model\\iris-071-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4256 - accuracy: 0.9583 - val_loss: 0.3155 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4865 - accuracy: 0.9062\n",
      "Epoch 72: val_loss did not improve from 0.31545\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4349 - accuracy: 0.9375 - val_loss: 0.3246 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5310 - accuracy: 0.9375\n",
      "Epoch 73: val_loss did not improve from 0.31545\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4803 - accuracy: 0.9375 - val_loss: 0.3634 - val_accuracy: 0.9583\n",
      "Epoch 74/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3364 - accuracy: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.31545\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4205 - accuracy: 0.9792 - val_loss: 0.3376 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4025 - accuracy: 0.9688\n",
      "Epoch 75: val_loss did not improve from 0.31545\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3971 - accuracy: 0.9583 - val_loss: 0.3165 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4011 - accuracy: 0.9688\n",
      "Epoch 76: val_loss improved from 0.31545 to 0.30774, saving model to ./model\\iris-076-val1.0000.h5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4690 - accuracy: 0.9583 - val_loss: 0.3077 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4611 - accuracy: 0.9688\n",
      "Epoch 77: val_loss did not improve from 0.30774\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4196 - accuracy: 0.9583 - val_loss: 0.3144 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4265 - accuracy: 0.9688\n",
      "Epoch 78: val_loss did not improve from 0.30774\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4315 - accuracy: 0.9479 - val_loss: 0.3599 - val_accuracy: 0.9583\n",
      "Epoch 79/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5638 - accuracy: 0.8438\n",
      "Epoch 79: val_loss did not improve from 0.30774\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4743 - accuracy: 0.9062 - val_loss: 0.3520 - val_accuracy: 0.9583\n",
      "Epoch 80/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6774 - accuracy: 0.9375\n",
      "Epoch 80: val_loss did not improve from 0.30774\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4488 - accuracy: 0.9688 - val_loss: 0.3132 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6699 - accuracy: 0.9062\n",
      "Epoch 81: val_loss improved from 0.30774 to 0.30513, saving model to ./model\\iris-081-val1.0000.h5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.4128 - accuracy: 0.9688 - val_loss: 0.3051 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3920 - accuracy: 0.9375\n",
      "Epoch 82: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4248 - accuracy: 0.9583 - val_loss: 0.3077 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4515 - accuracy: 0.9688\n",
      "Epoch 83: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4288 - accuracy: 0.9583 - val_loss: 0.3215 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4672 - accuracy: 0.9062\n",
      "Epoch 84: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4395 - accuracy: 0.9167 - val_loss: 0.3112 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5267 - accuracy: 0.9062\n",
      "Epoch 85: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4270 - accuracy: 0.9479 - val_loss: 0.3067 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2969 - accuracy: 0.9375\n",
      "Epoch 86: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4073 - accuracy: 0.9375 - val_loss: 0.3056 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4451 - accuracy: 0.9688\n",
      "Epoch 87: val_loss did not improve from 0.30513\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4172 - accuracy: 0.9792 - val_loss: 0.3064 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2161 - accuracy: 0.9688\n",
      "Epoch 88: val_loss improved from 0.30513 to 0.30071, saving model to ./model\\iris-088-val1.0000.h5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3663 - accuracy: 0.9792 - val_loss: 0.3007 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3660 - accuracy: 1.0000\n",
      "Epoch 89: val_loss did not improve from 0.30071\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4245 - accuracy: 0.9479 - val_loss: 0.3055 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3387 - accuracy: 0.9062\n",
      "Epoch 90: val_loss did not improve from 0.30071\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3769 - accuracy: 0.9375 - val_loss: 0.3212 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4781 - accuracy: 0.9375\n",
      "Epoch 91: val_loss improved from 0.30071 to 0.29209, saving model to ./model\\iris-091-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4339 - accuracy: 0.9375 - val_loss: 0.2921 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3380 - accuracy: 0.9688\n",
      "Epoch 92: val_loss improved from 0.29209 to 0.28790, saving model to ./model\\iris-092-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4046 - accuracy: 0.9479 - val_loss: 0.2879 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3335 - accuracy: 0.9375\n",
      "Epoch 93: val_loss did not improve from 0.28790\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3664 - accuracy: 0.9583 - val_loss: 0.3093 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4009 - accuracy: 1.0000\n",
      "Epoch 94: val_loss did not improve from 0.28790\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3632 - accuracy: 0.9792 - val_loss: 0.3072 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3919 - accuracy: 0.9062\n",
      "Epoch 95: val_loss improved from 0.28790 to 0.28685, saving model to ./model\\iris-095-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4434 - accuracy: 0.9479 - val_loss: 0.2869 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4121 - accuracy: 0.9688\n",
      "Epoch 96: val_loss did not improve from 0.28685\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.9688 - val_loss: 0.2945 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4048 - accuracy: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.28685\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3862 - accuracy: 0.9583 - val_loss: 0.3200 - val_accuracy: 0.9583\n",
      "Epoch 98/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3274 - accuracy: 0.9688\n",
      "Epoch 98: val_loss did not improve from 0.28685\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4023 - accuracy: 0.9479 - val_loss: 0.2908 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3490 - accuracy: 1.0000\n",
      "Epoch 99: val_loss improved from 0.28685 to 0.28125, saving model to ./model\\iris-099-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3412 - accuracy: 0.9792 - val_loss: 0.2813 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4196 - accuracy: 0.9688\n",
      "Epoch 100: val_loss did not improve from 0.28125\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3929 - accuracy: 0.9583 - val_loss: 0.3013 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3266 - accuracy: 0.9688\n",
      "Epoch 101: val_loss did not improve from 0.28125\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3712 - accuracy: 0.9792 - val_loss: 0.3207 - val_accuracy: 0.9583\n",
      "Epoch 102/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3770 - accuracy: 0.9375\n",
      "Epoch 102: val_loss improved from 0.28125 to 0.28123, saving model to ./model\\iris-102-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3954 - accuracy: 0.9479 - val_loss: 0.2812 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4217 - accuracy: 1.0000\n",
      "Epoch 103: val_loss improved from 0.28123 to 0.27187, saving model to ./model\\iris-103-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3622 - accuracy: 0.9688 - val_loss: 0.2719 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3523 - accuracy: 0.9688\n",
      "Epoch 104: val_loss did not improve from 0.27187\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3479 - accuracy: 0.9688 - val_loss: 0.2806 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4278 - accuracy: 0.9688\n",
      "Epoch 105: val_loss did not improve from 0.27187\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3664 - accuracy: 0.9583 - val_loss: 0.3064 - val_accuracy: 0.9583\n",
      "Epoch 106/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2926 - accuracy: 0.9688\n",
      "Epoch 106: val_loss did not improve from 0.27187\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3807 - accuracy: 0.9375 - val_loss: 0.3079 - val_accuracy: 0.9583\n",
      "Epoch 107/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3455 - accuracy: 0.9688\n",
      "Epoch 107: val_loss did not improve from 0.27187\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3659 - accuracy: 0.9583 - val_loss: 0.2723 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3614 - accuracy: 0.9688\n",
      "Epoch 108: val_loss improved from 0.27187 to 0.26655, saving model to ./model\\iris-108-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3445 - accuracy: 0.9792 - val_loss: 0.2665 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2776 - accuracy: 1.0000\n",
      "Epoch 109: val_loss did not improve from 0.26655\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3956 - accuracy: 0.9688 - val_loss: 0.2822 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3632 - accuracy: 0.9375\n",
      "Epoch 110: val_loss did not improve from 0.26655\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4172 - accuracy: 0.9375 - val_loss: 0.3478 - val_accuracy: 0.9583\n",
      "Epoch 111/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2812 - accuracy: 1.0000\n",
      "Epoch 111: val_loss did not improve from 0.26655\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3945 - accuracy: 0.9479 - val_loss: 0.3120 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4447 - accuracy: 0.9375\n",
      "Epoch 112: val_loss improved from 0.26655 to 0.26381, saving model to ./model\\iris-112-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4208 - accuracy: 0.9479 - val_loss: 0.2638 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4679 - accuracy: 0.9062\n",
      "Epoch 113: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3759 - accuracy: 0.9479 - val_loss: 0.2642 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5272 - accuracy: 0.9375\n",
      "Epoch 114: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3685 - accuracy: 0.9688 - val_loss: 0.2841 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4175 - accuracy: 0.9375\n",
      "Epoch 115: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3666 - accuracy: 0.9583 - val_loss: 0.2874 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9688\n",
      "Epoch 116: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3757 - accuracy: 0.9688 - val_loss: 0.2662 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2883 - accuracy: 0.9375\n",
      "Epoch 117: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3740 - accuracy: 0.9583 - val_loss: 0.2756 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2854 - accuracy: 0.9688\n",
      "Epoch 118: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3150 - accuracy: 0.9792 - val_loss: 0.2736 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3352 - accuracy: 0.9688\n",
      "Epoch 119: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3340 - accuracy: 0.9583 - val_loss: 0.2675 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4857 - accuracy: 0.9375\n",
      "Epoch 120: val_loss did not improve from 0.26381\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3930 - accuracy: 0.9583 - val_loss: 0.2674 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4363 - accuracy: 0.9688\n",
      "Epoch 121: val_loss improved from 0.26381 to 0.26365, saving model to ./model\\iris-121-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3134 - accuracy: 0.9792 - val_loss: 0.2636 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3644 - accuracy: 0.9375\n",
      "Epoch 122: val_loss did not improve from 0.26365\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3454 - accuracy: 0.9688 - val_loss: 0.2784 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2340 - accuracy: 0.9688\n",
      "Epoch 123: val_loss did not improve from 0.26365\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3494 - accuracy: 0.9792 - val_loss: 0.2662 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2512 - accuracy: 0.9688\n",
      "Epoch 124: val_loss improved from 0.26365 to 0.26333, saving model to ./model\\iris-124-val1.0000.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3834 - accuracy: 0.9688 - val_loss: 0.2633 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2928 - accuracy: 0.9688\n",
      "Epoch 125: val_loss improved from 0.26333 to 0.26114, saving model to ./model\\iris-125-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3540 - accuracy: 0.9583 - val_loss: 0.2611 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2899 - accuracy: 1.0000\n",
      "Epoch 126: val_loss did not improve from 0.26114\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2905 - accuracy: 0.9896 - val_loss: 0.2643 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3766 - accuracy: 0.9688\n",
      "Epoch 127: val_loss improved from 0.26114 to 0.25891, saving model to ./model\\iris-127-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3062 - accuracy: 0.9792 - val_loss: 0.2589 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2649 - accuracy: 1.0000\n",
      "Epoch 128: val_loss improved from 0.25891 to 0.25347, saving model to ./model\\iris-128-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3512 - accuracy: 0.9688 - val_loss: 0.2535 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2448 - accuracy: 0.9688\n",
      "Epoch 129: val_loss did not improve from 0.25347\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3072 - accuracy: 0.9792 - val_loss: 0.2641 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3238 - accuracy: 1.0000\n",
      "Epoch 130: val_loss improved from 0.25347 to 0.25001, saving model to ./model\\iris-130-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3342 - accuracy: 0.9792 - val_loss: 0.2500 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4254 - accuracy: 0.9375\n",
      "Epoch 131: val_loss did not improve from 0.25001\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3543 - accuracy: 0.9688 - val_loss: 0.2637 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3624 - accuracy: 1.0000\n",
      "Epoch 132: val_loss did not improve from 0.25001\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3035 - accuracy: 0.9792 - val_loss: 0.2616 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4534 - accuracy: 0.9375\n",
      "Epoch 133: val_loss improved from 0.25001 to 0.24771, saving model to ./model\\iris-133-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3712 - accuracy: 0.9375 - val_loss: 0.2477 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2613 - accuracy: 0.9062\n",
      "Epoch 134: val_loss improved from 0.24771 to 0.24710, saving model to ./model\\iris-134-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2975 - accuracy: 0.9688 - val_loss: 0.2471 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2691 - accuracy: 1.0000\n",
      "Epoch 135: val_loss improved from 0.24710 to 0.24368, saving model to ./model\\iris-135-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3023 - accuracy: 0.9792 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4004 - accuracy: 0.9688\n",
      "Epoch 136: val_loss improved from 0.24368 to 0.24288, saving model to ./model\\iris-136-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3095 - accuracy: 0.9688 - val_loss: 0.2429 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1989 - accuracy: 1.0000\n",
      "Epoch 137: val_loss did not improve from 0.24288\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3349 - accuracy: 0.9792 - val_loss: 0.2436 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3334 - accuracy: 1.0000\n",
      "Epoch 138: val_loss did not improve from 0.24288\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3217 - accuracy: 0.9792 - val_loss: 0.2698 - val_accuracy: 0.9583\n",
      "Epoch 139/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3285 - accuracy: 0.9688\n",
      "Epoch 139: val_loss did not improve from 0.24288\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3167 - accuracy: 0.9583 - val_loss: 0.2911 - val_accuracy: 0.9583\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3447 - accuracy: 0.9688\n",
      "Epoch 140: val_loss did not improve from 0.24288\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3270 - accuracy: 0.9583 - val_loss: 0.2459 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3331 - accuracy: 0.9375\n",
      "Epoch 141: val_loss improved from 0.24288 to 0.23497, saving model to ./model\\iris-141-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3630 - accuracy: 0.9583 - val_loss: 0.2350 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 142: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3029 - accuracy: 0.9792 - val_loss: 0.2438 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2977 - accuracy: 1.0000\n",
      "Epoch 143: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3567 - accuracy: 0.9792 - val_loss: 0.2701 - val_accuracy: 0.9583\n",
      "Epoch 144/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3421 - accuracy: 0.9062\n",
      "Epoch 144: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3351 - accuracy: 0.9583 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2385 - accuracy: 1.0000\n",
      "Epoch 145: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3227 - accuracy: 0.9792 - val_loss: 0.2395 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2806 - accuracy: 1.0000\n",
      "Epoch 146: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3052 - accuracy: 0.9792 - val_loss: 0.2403 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4014 - accuracy: 0.9375\n",
      "Epoch 147: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3035 - accuracy: 0.9583 - val_loss: 0.2449 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2587 - accuracy: 1.0000\n",
      "Epoch 148: val_loss did not improve from 0.23497\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3064 - accuracy: 0.9792 - val_loss: 0.2401 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2885 - accuracy: 0.9688\n",
      "Epoch 149: val_loss improved from 0.23497 to 0.22954, saving model to ./model\\iris-149-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3269 - accuracy: 0.9792 - val_loss: 0.2295 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2572 - accuracy: 1.0000\n",
      "Epoch 150: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2983 - accuracy: 0.9792 - val_loss: 0.2374 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3862 - accuracy: 0.9375\n",
      "Epoch 151: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3287 - accuracy: 0.9688 - val_loss: 0.2402 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3080 - accuracy: 0.9375\n",
      "Epoch 152: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2819 - accuracy: 0.9792 - val_loss: 0.2410 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2426 - accuracy: 1.0000\n",
      "Epoch 153: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2971 - accuracy: 0.9792 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3009 - accuracy: 0.9688\n",
      "Epoch 154: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2879 - accuracy: 0.9896 - val_loss: 0.2359 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3872 - accuracy: 0.9688\n",
      "Epoch 155: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3256 - accuracy: 0.9792 - val_loss: 0.2358 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3296 - accuracy: 0.9688\n",
      "Epoch 156: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3423 - accuracy: 0.9583 - val_loss: 0.2325 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3702 - accuracy: 0.9062\n",
      "Epoch 157: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3050 - accuracy: 0.9583 - val_loss: 0.2362 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2922 - accuracy: 1.0000\n",
      "Epoch 158: val_loss did not improve from 0.22954\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2806 - accuracy: 0.9792 - val_loss: 0.2311 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2078 - accuracy: 0.9688\n",
      "Epoch 159: val_loss improved from 0.22954 to 0.22307, saving model to ./model\\iris-159-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3104 - accuracy: 0.9583 - val_loss: 0.2231 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1933 - accuracy: 1.0000\n",
      "Epoch 160: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2620 - accuracy: 0.9896 - val_loss: 0.2264 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2978 - accuracy: 0.9688\n",
      "Epoch 161: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3134 - accuracy: 0.9792 - val_loss: 0.2356 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3769 - accuracy: 0.9688\n",
      "Epoch 162: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3034 - accuracy: 0.9688 - val_loss: 0.2305 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2546 - accuracy: 1.0000\n",
      "Epoch 163: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3037 - accuracy: 0.9896 - val_loss: 0.2237 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2696 - accuracy: 0.9688\n",
      "Epoch 164: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3223 - accuracy: 0.9688 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3239 - accuracy: 0.9375\n",
      "Epoch 165: val_loss did not improve from 0.22307\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2847 - accuracy: 0.9688 - val_loss: 0.2282 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2498 - accuracy: 1.0000\n",
      "Epoch 166: val_loss improved from 0.22307 to 0.21467, saving model to ./model\\iris-166-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2999 - accuracy: 0.9896 - val_loss: 0.2147 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3133 - accuracy: 0.9688\n",
      "Epoch 167: val_loss did not improve from 0.21467\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3074 - accuracy: 0.9688 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2431 - accuracy: 0.9688\n",
      "Epoch 168: val_loss did not improve from 0.21467\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2927 - accuracy: 0.9583 - val_loss: 0.2293 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2274 - accuracy: 1.0000\n",
      "Epoch 169: val_loss did not improve from 0.21467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2828 - accuracy: 0.9792 - val_loss: 0.2389 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3421 - accuracy: 0.9375\n",
      "Epoch 170: val_loss did not improve from 0.21467\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2697 - accuracy: 0.9688 - val_loss: 0.2197 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3293 - accuracy: 0.9688\n",
      "Epoch 171: val_loss improved from 0.21467 to 0.21274, saving model to ./model\\iris-171-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3230 - accuracy: 0.9792 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2130 - accuracy: 1.0000\n",
      "Epoch 172: val_loss did not improve from 0.21274\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3060 - accuracy: 0.9792 - val_loss: 0.2161 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3050 - accuracy: 0.9688\n",
      "Epoch 173: val_loss did not improve from 0.21274\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2860 - accuracy: 0.9375 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2484 - accuracy: 1.0000\n",
      "Epoch 174: val_loss did not improve from 0.21274\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2998 - accuracy: 0.9479 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3122 - accuracy: 0.9688\n",
      "Epoch 175: val_loss improved from 0.21274 to 0.20923, saving model to ./model\\iris-175-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2624 - accuracy: 0.9792 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2968 - accuracy: 0.9688\n",
      "Epoch 176: val_loss improved from 0.20923 to 0.20433, saving model to ./model\\iris-176-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2799 - accuracy: 0.9792 - val_loss: 0.2043 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2914 - accuracy: 0.9688\n",
      "Epoch 177: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2767 - accuracy: 0.9792 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2933 - accuracy: 1.0000\n",
      "Epoch 178: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2996 - accuracy: 0.9896 - val_loss: 0.2279 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2081 - accuracy: 1.0000\n",
      "Epoch 179: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2886 - accuracy: 0.9688 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9688\n",
      "Epoch 180: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2639 - accuracy: 0.9792 - val_loss: 0.2209 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2520 - accuracy: 1.0000\n",
      "Epoch 181: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2691 - accuracy: 0.9896 - val_loss: 0.2099 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1693 - accuracy: 1.0000\n",
      "Epoch 182: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2586 - accuracy: 0.9792 - val_loss: 0.2177 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4022 - accuracy: 0.9375\n",
      "Epoch 183: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2993 - accuracy: 0.9583 - val_loss: 0.2348 - val_accuracy: 0.9583\n",
      "Epoch 184/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2235 - accuracy: 1.0000\n",
      "Epoch 184: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2857 - accuracy: 0.9688 - val_loss: 0.2155 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1994 - accuracy: 1.0000\n",
      "Epoch 185: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2617 - accuracy: 0.9896 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3389 - accuracy: 0.9688\n",
      "Epoch 186: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2653 - accuracy: 0.9792 - val_loss: 0.2083 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1834 - accuracy: 1.0000\n",
      "Epoch 187: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2478 - accuracy: 0.9896 - val_loss: 0.2151 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2277 - accuracy: 1.0000\n",
      "Epoch 188: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2987 - accuracy: 0.9583 - val_loss: 0.2080 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1954 - accuracy: 1.0000\n",
      "Epoch 189: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2705 - accuracy: 0.9896 - val_loss: 0.2047 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3298 - accuracy: 0.9375\n",
      "Epoch 190: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2800 - accuracy: 0.9792 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2113 - accuracy: 0.9688\n",
      "Epoch 191: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2733 - accuracy: 0.9792 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3064 - accuracy: 1.0000\n",
      "Epoch 192: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2646 - accuracy: 0.9896 - val_loss: 0.2116 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9688\n",
      "Epoch 193: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2480 - accuracy: 0.9792 - val_loss: 0.2166 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2932 - accuracy: 1.0000\n",
      "Epoch 194: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2382 - accuracy: 0.9896 - val_loss: 0.2098 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2750 - accuracy: 0.9688\n",
      "Epoch 195: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2852 - accuracy: 0.9688 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2072 - accuracy: 1.0000\n",
      "Epoch 196: val_loss did not improve from 0.20433\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2495 - accuracy: 0.9792 - val_loss: 0.2145 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1955 - accuracy: 0.9688\n",
      "Epoch 197: val_loss improved from 0.20433 to 0.20025, saving model to ./model\\iris-197-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2308 - accuracy: 0.9896 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2363 - accuracy: 0.9688\n",
      "Epoch 198: val_loss improved from 0.20025 to 0.19228, saving model to ./model\\iris-198-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2382 - accuracy: 0.9896 - val_loss: 0.1923 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 199: val_loss improved from 0.19228 to 0.19162, saving model to ./model\\iris-199-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2680 - accuracy: 0.9896 - val_loss: 0.1916 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2258 - accuracy: 0.9688\n",
      "Epoch 200: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2618 - accuracy: 0.9792 - val_loss: 0.2167 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1881 - accuracy: 1.0000\n",
      "Epoch 201: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2729 - accuracy: 0.9688 - val_loss: 0.2055 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2330 - accuracy: 1.0000\n",
      "Epoch 202: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2398 - accuracy: 0.9792 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2142 - accuracy: 1.0000\n",
      "Epoch 203: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2488 - accuracy: 0.9792 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3173 - accuracy: 0.9375\n",
      "Epoch 204: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2831 - accuracy: 0.9583 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2612 - accuracy: 0.9688\n",
      "Epoch 205: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2467 - accuracy: 0.9792 - val_loss: 0.2017 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2053 - accuracy: 1.0000\n",
      "Epoch 206: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2508 - accuracy: 0.9896 - val_loss: 0.1932 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1883 - accuracy: 1.0000\n",
      "Epoch 207: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2536 - accuracy: 0.9896 - val_loss: 0.1971 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2062 - accuracy: 1.0000\n",
      "Epoch 208: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2442 - accuracy: 0.9688 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4161 - accuracy: 0.9375\n",
      "Epoch 209: val_loss did not improve from 0.19162\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2859 - accuracy: 0.9583 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2194 - accuracy: 1.0000\n",
      "Epoch 210: val_loss improved from 0.19162 to 0.18531, saving model to ./model\\iris-210-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2400 - accuracy: 0.9896 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2225 - accuracy: 1.0000\n",
      "Epoch 211: val_loss did not improve from 0.18531\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2679 - accuracy: 0.9583 - val_loss: 0.1953 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1481 - accuracy: 1.0000\n",
      "Epoch 212: val_loss did not improve from 0.18531\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2506 - accuracy: 0.9688 - val_loss: 0.2256 - val_accuracy: 0.9583\n",
      "Epoch 213/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2684 - accuracy: 0.9375\n",
      "Epoch 213: val_loss did not improve from 0.18531\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2664 - accuracy: 0.9583 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3688 - accuracy: 0.9688\n",
      "Epoch 214: val_loss did not improve from 0.18531\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2715 - accuracy: 0.9688 - val_loss: 0.1872 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2949 - accuracy: 0.9688\n",
      "Epoch 215: val_loss improved from 0.18531 to 0.18207, saving model to ./model\\iris-215-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2339 - accuracy: 0.9792 - val_loss: 0.1821 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2346 - accuracy: 1.0000\n",
      "Epoch 216: val_loss did not improve from 0.18207\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2538 - accuracy: 0.9896 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2715 - accuracy: 0.9375\n",
      "Epoch 217: val_loss did not improve from 0.18207\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2631 - accuracy: 0.9583 - val_loss: 0.2101 - val_accuracy: 0.9583\n",
      "Epoch 218/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 218: val_loss did not improve from 0.18207\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2528 - accuracy: 0.9792 - val_loss: 0.2237 - val_accuracy: 0.9583\n",
      "Epoch 219/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3227 - accuracy: 0.9688\n",
      "Epoch 219: val_loss did not improve from 0.18207\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2622 - accuracy: 0.9896 - val_loss: 0.2037 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2219 - accuracy: 0.9688\n",
      "Epoch 220: val_loss improved from 0.18207 to 0.18081, saving model to ./model\\iris-220-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2734 - accuracy: 0.9688 - val_loss: 0.1808 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3063 - accuracy: 0.9375\n",
      "Epoch 221: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2434 - accuracy: 0.9688 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2101 - accuracy: 1.0000\n",
      "Epoch 222: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2428 - accuracy: 0.9896 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9688\n",
      "Epoch 223: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2594 - accuracy: 0.9583 - val_loss: 0.1889 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2513 - accuracy: 1.0000\n",
      "Epoch 224: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2368 - accuracy: 0.9792 - val_loss: 0.1834 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1835 - accuracy: 0.9688\n",
      "Epoch 225: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2371 - accuracy: 0.9792 - val_loss: 0.1991 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3499 - accuracy: 0.9375\n",
      "Epoch 226: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2581 - accuracy: 0.9792 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3638 - accuracy: 0.9688\n",
      "Epoch 227: val_loss did not improve from 0.18081\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2536 - accuracy: 0.9792 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2210 - accuracy: 0.9688\n",
      "Epoch 228: val_loss improved from 0.18081 to 0.17605, saving model to ./model\\iris-228-val1.0000.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2370 - accuracy: 0.9688 - val_loss: 0.1760 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2012 - accuracy: 1.0000\n",
      "Epoch 229: val_loss did not improve from 0.17605\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2533 - accuracy: 0.9688 - val_loss: 0.1764 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2637 - accuracy: 0.9688\n",
      "Epoch 230: val_loss did not improve from 0.17605\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2320 - accuracy: 0.9792 - val_loss: 0.1949 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9688\n",
      "Epoch 231: val_loss did not improve from 0.17605\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2446 - accuracy: 0.9688 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1329 - accuracy: 1.0000\n",
      "Epoch 232: val_loss improved from 0.17605 to 0.17174, saving model to ./model\\iris-232-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2319 - accuracy: 0.9688 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2242 - accuracy: 1.0000\n",
      "Epoch 233: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2572 - accuracy: 0.9583 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2884 - accuracy: 0.9688\n",
      "Epoch 234: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2278 - accuracy: 0.9896 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1800 - accuracy: 1.0000\n",
      "Epoch 235: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2461 - accuracy: 0.9688 - val_loss: 0.1823 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3647 - accuracy: 0.9375\n",
      "Epoch 236: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2359 - accuracy: 0.9792 - val_loss: 0.1903 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2714 - accuracy: 0.9688\n",
      "Epoch 237: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2271 - accuracy: 0.9896 - val_loss: 0.1893 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1485 - accuracy: 1.0000\n",
      "Epoch 238: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2334 - accuracy: 0.9792 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3634 - accuracy: 0.9688\n",
      "Epoch 239: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2436 - accuracy: 0.9896 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1487 - accuracy: 1.0000\n",
      "Epoch 240: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2287 - accuracy: 0.9792 - val_loss: 0.1810 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4469 - accuracy: 0.9688\n",
      "Epoch 241: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2569 - accuracy: 0.9896 - val_loss: 0.1902 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9688\n",
      "Epoch 242: val_loss did not improve from 0.17174\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2176 - accuracy: 0.9792 - val_loss: 0.1796 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1656 - accuracy: 1.0000\n",
      "Epoch 243: val_loss improved from 0.17174 to 0.16782, saving model to ./model\\iris-243-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2497 - accuracy: 0.9792 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 244: val_loss did not improve from 0.16782\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2504 - accuracy: 0.9688 - val_loss: 0.1760 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2128 - accuracy: 1.0000\n",
      "Epoch 245: val_loss did not improve from 0.16782\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2222 - accuracy: 0.9688 - val_loss: 0.1906 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2394 - accuracy: 0.9688\n",
      "Epoch 246: val_loss did not improve from 0.16782\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2124 - accuracy: 0.9896 - val_loss: 0.1734 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9375\n",
      "Epoch 247: val_loss improved from 0.16782 to 0.16690, saving model to ./model\\iris-247-val1.0000.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2155 - accuracy: 0.9792 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1554 - accuracy: 1.0000\n",
      "Epoch 248: val_loss improved from 0.16690 to 0.16614, saving model to ./model\\iris-248-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2040 - accuracy: 0.9896 - val_loss: 0.1661 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2554 - accuracy: 0.9688\n",
      "Epoch 249: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2313 - accuracy: 0.9896 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 250: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2318 - accuracy: 0.9792 - val_loss: 0.1852 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2938 - accuracy: 0.9375\n",
      "Epoch 251: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2139 - accuracy: 0.9688 - val_loss: 0.1666 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1744 - accuracy: 1.0000\n",
      "Epoch 252: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2156 - accuracy: 0.9792 - val_loss: 0.1675 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1760 - accuracy: 1.0000\n",
      "Epoch 253: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2239 - accuracy: 0.9896 - val_loss: 0.1758 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1898 - accuracy: 1.0000\n",
      "Epoch 254: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2168 - accuracy: 0.9896 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1724 - accuracy: 0.9688\n",
      "Epoch 255: val_loss did not improve from 0.16614\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2133 - accuracy: 0.9792 - val_loss: 0.1690 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1390 - accuracy: 1.0000\n",
      "Epoch 256: val_loss improved from 0.16614 to 0.16501, saving model to ./model\\iris-256-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1923 - accuracy: 0.9896 - val_loss: 0.1650 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1809 - accuracy: 1.0000\n",
      "Epoch 257: val_loss improved from 0.16501 to 0.16316, saving model to ./model\\iris-257-val1.0000.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2045 - accuracy: 0.9896 - val_loss: 0.1632 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3170 - accuracy: 0.9688\n",
      "Epoch 258: val_loss did not improve from 0.16316\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2238 - accuracy: 0.9792 - val_loss: 0.1720 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2287 - accuracy: 0.9688\n",
      "Epoch 259: val_loss did not improve from 0.16316\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2292 - accuracy: 0.9688 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1493 - accuracy: 0.9688\n",
      "Epoch 260: val_loss improved from 0.16316 to 0.16221, saving model to ./model\\iris-260-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2235 - accuracy: 0.9792 - val_loss: 0.1622 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2416 - accuracy: 0.9375\n",
      "Epoch 261: val_loss did not improve from 0.16221\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2122 - accuracy: 0.9688 - val_loss: 0.1661 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2335 - accuracy: 0.9688\n",
      "Epoch 262: val_loss did not improve from 0.16221\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2378 - accuracy: 0.9583 - val_loss: 0.1878 - val_accuracy: 0.9583\n",
      "Epoch 263/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2479 - accuracy: 0.9375\n",
      "Epoch 263: val_loss did not improve from 0.16221\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2181 - accuracy: 0.9688 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2403 - accuracy: 0.9688\n",
      "Epoch 264: val_loss improved from 0.16221 to 0.16184, saving model to ./model\\iris-264-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2086 - accuracy: 0.9688 - val_loss: 0.1618 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2800 - accuracy: 0.9688\n",
      "Epoch 265: val_loss improved from 0.16184 to 0.16096, saving model to ./model\\iris-265-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2237 - accuracy: 0.9792 - val_loss: 0.1610 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3118 - accuracy: 0.9688\n",
      "Epoch 266: val_loss did not improve from 0.16096\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2225 - accuracy: 0.9896 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2069 - accuracy: 0.9688\n",
      "Epoch 267: val_loss did not improve from 0.16096\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2242 - accuracy: 0.9688 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1950 - accuracy: 1.0000\n",
      "Epoch 268: val_loss did not improve from 0.16096\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2227 - accuracy: 0.9792 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1678 - accuracy: 1.0000\n",
      "Epoch 269: val_loss did not improve from 0.16096\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2111 - accuracy: 0.9688 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1801 - accuracy: 1.0000\n",
      "Epoch 270: val_loss improved from 0.16096 to 0.15519, saving model to ./model\\iris-270-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1874 - accuracy: 0.9896 - val_loss: 0.1552 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1483 - accuracy: 1.0000\n",
      "Epoch 271: val_loss improved from 0.15519 to 0.15372, saving model to ./model\\iris-271-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1864 - accuracy: 0.9792 - val_loss: 0.1537 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2244 - accuracy: 0.9688\n",
      "Epoch 272: val_loss did not improve from 0.15372\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2121 - accuracy: 0.9792 - val_loss: 0.1674 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2297 - accuracy: 1.0000\n",
      "Epoch 273: val_loss did not improve from 0.15372\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1907 - accuracy: 0.9896 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2370 - accuracy: 0.9375\n",
      "Epoch 274: val_loss improved from 0.15372 to 0.15069, saving model to ./model\\iris-274-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1945 - accuracy: 0.9583 - val_loss: 0.1507 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1631 - accuracy: 1.0000\n",
      "Epoch 275: val_loss improved from 0.15069 to 0.14458, saving model to ./model\\iris-275-val1.0000.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2147 - accuracy: 0.9792 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1791 - accuracy: 0.9688\n",
      "Epoch 276: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2029 - accuracy: 0.9792 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1718 - accuracy: 0.9688\n",
      "Epoch 277: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1910 - accuracy: 0.9792 - val_loss: 0.1677 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1588 - accuracy: 1.0000\n",
      "Epoch 278: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1867 - accuracy: 0.9792 - val_loss: 0.1676 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1567 - accuracy: 1.0000\n",
      "Epoch 279: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2069 - accuracy: 0.9792 - val_loss: 0.1485 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2260 - accuracy: 0.9688\n",
      "Epoch 280: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2005 - accuracy: 0.9792 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1878 - accuracy: 0.9688\n",
      "Epoch 281: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2185 - accuracy: 0.9792 - val_loss: 0.1619 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 282: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1975 - accuracy: 0.9896 - val_loss: 0.1663 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2418 - accuracy: 0.9688\n",
      "Epoch 283: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9896 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1696 - accuracy: 1.0000\n",
      "Epoch 284: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1850 - accuracy: 0.9792 - val_loss: 0.1502 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1484 - accuracy: 1.0000\n",
      "Epoch 285: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2098 - accuracy: 0.9896 - val_loss: 0.1620 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 286: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1914 - accuracy: 0.9896 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1796 - accuracy: 1.0000\n",
      "Epoch 287: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2162 - accuracy: 0.9688 - val_loss: 0.1474 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1617 - accuracy: 1.0000\n",
      "Epoch 288: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2012 - accuracy: 0.9792 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3493 - accuracy: 0.9375\n",
      "Epoch 289: val_loss did not improve from 0.14458\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2367 - accuracy: 0.9583 - val_loss: 0.1775 - val_accuracy: 0.9583\n",
      "Epoch 290/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2852 - accuracy: 0.9375\n",
      "Epoch 290: val_loss improved from 0.14458 to 0.14380, saving model to ./model\\iris-290-val1.0000.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2041 - accuracy: 0.9688 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1788 - accuracy: 1.0000\n",
      "Epoch 291: val_loss improved from 0.14380 to 0.13955, saving model to ./model\\iris-291-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1880 - accuracy: 0.9792 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2012 - accuracy: 0.9688\n",
      "Epoch 292: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1663 - accuracy: 0.9896 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 293: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1964 - accuracy: 0.9896 - val_loss: 0.1588 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1974 - accuracy: 1.0000\n",
      "Epoch 294: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1743 - accuracy: 0.9896 - val_loss: 0.1496 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1165 - accuracy: 1.0000\n",
      "Epoch 295: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1996 - accuracy: 0.9896 - val_loss: 0.1581 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1667 - accuracy: 1.0000\n",
      "Epoch 296: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2114 - accuracy: 0.9688 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1457 - accuracy: 1.0000\n",
      "Epoch 297: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2154 - accuracy: 0.9792 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1900 - accuracy: 0.9688\n",
      "Epoch 298: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2248 - accuracy: 0.9688 - val_loss: 0.1663 - val_accuracy: 0.9583\n",
      "Epoch 299/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 299: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2105 - accuracy: 0.9688 - val_loss: 0.1918 - val_accuracy: 0.9583\n",
      "Epoch 300/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9688\n",
      "Epoch 300: val_loss did not improve from 0.13955\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1932 - accuracy: 0.9688 - val_loss: 0.1514 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1823 - accuracy: 1.0000\n",
      "Epoch 301: val_loss improved from 0.13955 to 0.13470, saving model to ./model\\iris-301-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1997 - accuracy: 0.9792 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3135 - accuracy: 0.9375\n",
      "Epoch 302: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2203 - accuracy: 0.9688 - val_loss: 0.1448 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1415 - accuracy: 1.0000\n",
      "Epoch 303: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1985 - accuracy: 0.9792 - val_loss: 0.1702 - val_accuracy: 0.9583\n",
      "Epoch 304/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1708 - accuracy: 0.9688\n",
      "Epoch 304: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2114 - accuracy: 0.9792 - val_loss: 0.1489 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1969 - accuracy: 1.0000\n",
      "Epoch 305: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2085 - accuracy: 0.9792 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1311 - accuracy: 1.0000\n",
      "Epoch 306: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1697 - accuracy: 0.9896 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1832 - accuracy: 1.0000\n",
      "Epoch 307: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1855 - accuracy: 0.9792 - val_loss: 0.1619 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2113 - accuracy: 0.9688\n",
      "Epoch 308: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1893 - accuracy: 0.9792 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000\n",
      "Epoch 309: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1872 - accuracy: 0.9792 - val_loss: 0.1384 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2045 - accuracy: 0.9688\n",
      "Epoch 310: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1712 - accuracy: 0.9896 - val_loss: 0.1395 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1365 - accuracy: 1.0000\n",
      "Epoch 311: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1699 - accuracy: 0.9896 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1962 - accuracy: 0.9688\n",
      "Epoch 312: val_loss did not improve from 0.13470\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1767 - accuracy: 0.9792 - val_loss: 0.1488 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1172 - accuracy: 1.0000\n",
      "Epoch 313: val_loss improved from 0.13470 to 0.13384, saving model to ./model\\iris-313-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1896 - accuracy: 0.9896 - val_loss: 0.1338 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1120 - accuracy: 1.0000\n",
      "Epoch 314: val_loss did not improve from 0.13384\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1955 - accuracy: 0.9688 - val_loss: 0.1346 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2633 - accuracy: 0.9688\n",
      "Epoch 315: val_loss did not improve from 0.13384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2253 - accuracy: 0.9688 - val_loss: 0.1574 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2854 - accuracy: 0.9375\n",
      "Epoch 316: val_loss did not improve from 0.13384\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2003 - accuracy: 0.9792 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2227 - accuracy: 0.9688\n",
      "Epoch 317: val_loss improved from 0.13384 to 0.13290, saving model to ./model\\iris-317-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1814 - accuracy: 0.9896 - val_loss: 0.1329 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1102 - accuracy: 1.0000\n",
      "Epoch 318: val_loss improved from 0.13290 to 0.12980, saving model to ./model\\iris-318-val1.0000.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1594 - accuracy: 0.9896 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1817 - accuracy: 0.9688\n",
      "Epoch 319: val_loss did not improve from 0.12980\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1636 - accuracy: 0.9792 - val_loss: 0.1389 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1488 - accuracy: 1.0000\n",
      "Epoch 320: val_loss did not improve from 0.12980\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1884 - accuracy: 0.9792 - val_loss: 0.1617 - val_accuracy: 0.9583\n",
      "Epoch 321/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3354 - accuracy: 0.9688\n",
      "Epoch 321: val_loss did not improve from 0.12980\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2088 - accuracy: 0.9688 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000\n",
      "Epoch 322: val_loss improved from 0.12980 to 0.12890, saving model to ./model\\iris-322-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1906 - accuracy: 0.9896 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1339 - accuracy: 1.0000\n",
      "Epoch 323: val_loss did not improve from 0.12890\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1837 - accuracy: 0.9896 - val_loss: 0.1311 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1554 - accuracy: 1.0000\n",
      "Epoch 324: val_loss did not improve from 0.12890\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1825 - accuracy: 0.9896 - val_loss: 0.1465 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1605 - accuracy: 1.0000\n",
      "Epoch 325: val_loss did not improve from 0.12890\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2098 - accuracy: 0.9688 - val_loss: 0.1586 - val_accuracy: 0.9583\n",
      "Epoch 326/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0999 - accuracy: 0.9688\n",
      "Epoch 326: val_loss did not improve from 0.12890\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1978 - accuracy: 0.9583 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0983 - accuracy: 1.0000\n",
      "Epoch 327: val_loss improved from 0.12890 to 0.12846, saving model to ./model\\iris-327-val1.0000.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2051 - accuracy: 0.9792 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1665 - accuracy: 0.9688\n",
      "Epoch 328: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1787 - accuracy: 0.9792 - val_loss: 0.1435 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9688\n",
      "Epoch 329: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1840 - accuracy: 0.9896 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1563 - accuracy: 1.0000\n",
      "Epoch 330: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1942 - accuracy: 0.9896 - val_loss: 0.1319 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 331: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1824 - accuracy: 0.9792 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 332: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1931 - accuracy: 0.9792 - val_loss: 0.1585 - val_accuracy: 0.9583\n",
      "Epoch 333/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1504 - accuracy: 1.0000\n",
      "Epoch 333: val_loss did not improve from 0.12846\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1687 - accuracy: 0.9896 - val_loss: 0.1432 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2154 - accuracy: 0.9375\n",
      "Epoch 334: val_loss improved from 0.12846 to 0.12781, saving model to ./model\\iris-334-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2087 - accuracy: 0.9688 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1238 - accuracy: 1.0000\n",
      "Epoch 335: val_loss improved from 0.12781 to 0.12631, saving model to ./model\\iris-335-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1772 - accuracy: 0.9896 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2719 - accuracy: 0.9375\n",
      "Epoch 336: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1950 - accuracy: 0.9688 - val_loss: 0.1603 - val_accuracy: 0.9583\n",
      "Epoch 337/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2049 - accuracy: 0.9688\n",
      "Epoch 337: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1984 - accuracy: 0.9688 - val_loss: 0.1490 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2220 - accuracy: 0.9688\n",
      "Epoch 338: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1736 - accuracy: 0.9792 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1288 - accuracy: 1.0000\n",
      "Epoch 339: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1663 - accuracy: 0.9792 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1193 - accuracy: 1.0000\n",
      "Epoch 340: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1699 - accuracy: 0.9792 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1231 - accuracy: 1.0000\n",
      "Epoch 341: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1676 - accuracy: 0.9896 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1735 - accuracy: 0.9688\n",
      "Epoch 342: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1649 - accuracy: 0.9792 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1287 - accuracy: 1.0000\n",
      "Epoch 343: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1757 - accuracy: 0.9896 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1145 - accuracy: 1.0000\n",
      "Epoch 344: val_loss did not improve from 0.12631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1850 - accuracy: 0.9896 - val_loss: 0.1454 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1691 - accuracy: 1.0000\n",
      "Epoch 345: val_loss did not improve from 0.12631\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1436 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 346: val_loss improved from 0.12631 to 0.12263, saving model to ./model\\iris-346-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1831 - accuracy: 0.9688 - val_loss: 0.1226 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1838 - accuracy: 0.9688\n",
      "Epoch 347: val_loss did not improve from 0.12263\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1873 - accuracy: 0.9792 - val_loss: 0.1277 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2057 - accuracy: 0.9688\n",
      "Epoch 348: val_loss did not improve from 0.12263\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1657 - accuracy: 0.9896 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1876 - accuracy: 0.9688\n",
      "Epoch 349: val_loss did not improve from 0.12263\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1524 - accuracy: 0.9896 - val_loss: 0.1407 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1749 - accuracy: 1.0000\n",
      "Epoch 350: val_loss improved from 0.12263 to 0.12189, saving model to ./model\\iris-350-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1804 - accuracy: 0.9896 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 351: val_loss improved from 0.12189 to 0.12159, saving model to ./model\\iris-351-val1.0000.h5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1808 - accuracy: 0.9896 - val_loss: 0.1216 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1360 - accuracy: 1.0000\n",
      "Epoch 352: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1859 - accuracy: 0.9896 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1017 - accuracy: 1.0000\n",
      "Epoch 353: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1468 - accuracy: 0.9896 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9688\n",
      "Epoch 354: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1753 - accuracy: 0.9792 - val_loss: 0.1251 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1329 - accuracy: 1.0000\n",
      "Epoch 355: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1756 - accuracy: 0.9896 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9688\n",
      "Epoch 356: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1654 - accuracy: 0.9896 - val_loss: 0.1283 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2949 - accuracy: 0.9688\n",
      "Epoch 357: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2016 - accuracy: 0.9792 - val_loss: 0.1507 - val_accuracy: 0.9583\n",
      "Epoch 358/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9375\n",
      "Epoch 358: val_loss did not improve from 0.12159\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1600 - accuracy: 0.9792 - val_loss: 0.1293 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1474 - accuracy: 1.0000\n",
      "Epoch 359: val_loss improved from 0.12159 to 0.12094, saving model to ./model\\iris-359-val1.0000.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1491 - accuracy: 0.9896 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 360: val_loss did not improve from 0.12094\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1680 - accuracy: 0.9792 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2295 - accuracy: 0.9688\n",
      "Epoch 361: val_loss did not improve from 0.12094\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9896 - val_loss: 0.1390 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1365 - accuracy: 1.0000\n",
      "Epoch 362: val_loss did not improve from 0.12094\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1490 - accuracy: 0.9896 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8750\n",
      "Epoch 363: val_loss improved from 0.12094 to 0.11445, saving model to ./model\\iris-363-val1.0000.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2001 - accuracy: 0.9479 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 364: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1730 - accuracy: 0.9792 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2040 - accuracy: 0.9688\n",
      "Epoch 365: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1609 - accuracy: 0.9896 - val_loss: 0.1471 - val_accuracy: 0.9583\n",
      "Epoch 366/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2417 - accuracy: 0.9375\n",
      "Epoch 366: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1658 - accuracy: 0.9792 - val_loss: 0.1277 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1581 - accuracy: 1.0000\n",
      "Epoch 367: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1528 - accuracy: 0.9896 - val_loss: 0.1149 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2585 - accuracy: 0.9688\n",
      "Epoch 368: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1743 - accuracy: 0.9792 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1519 - accuracy: 1.0000\n",
      "Epoch 369: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1530 - accuracy: 0.9896 - val_loss: 0.1398 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2415 - accuracy: 0.9688\n",
      "Epoch 370: val_loss did not improve from 0.11445\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1905 - accuracy: 0.9688 - val_loss: 0.1305 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1048 - accuracy: 1.0000\n",
      "Epoch 371: val_loss improved from 0.11445 to 0.11327, saving model to ./model\\iris-371-val1.0000.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1714 - accuracy: 0.9896 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2185 - accuracy: 0.9688\n",
      "Epoch 372: val_loss did not improve from 0.11327\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1693 - accuracy: 0.9896 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1947 - accuracy: 0.9688\n",
      "Epoch 373: val_loss did not improve from 0.11327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1505 - accuracy: 0.9896 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1283 - accuracy: 1.0000\n",
      "Epoch 374: val_loss did not improve from 0.11327\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1510 - accuracy: 0.9896 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1118 - accuracy: 1.0000\n",
      "Epoch 375: val_loss did not improve from 0.11327\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1493 - accuracy: 0.9896 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1623 - accuracy: 0.9688\n",
      "Epoch 376: val_loss improved from 0.11327 to 0.11160, saving model to ./model\\iris-376-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1611 - accuracy: 0.9792 - val_loss: 0.1116 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1046 - accuracy: 1.0000\n",
      "Epoch 377: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1688 - accuracy: 0.9896 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2297 - accuracy: 0.9688\n",
      "Epoch 378: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1603 - accuracy: 0.9896 - val_loss: 0.1314 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 379: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1733 - accuracy: 0.9792 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1272 - accuracy: 1.0000\n",
      "Epoch 380: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1613 - accuracy: 0.9896 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2662 - accuracy: 0.9375\n",
      "Epoch 381: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1850 - accuracy: 0.9583 - val_loss: 0.1164 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9688\n",
      "Epoch 382: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9792 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1380 - accuracy: 1.0000\n",
      "Epoch 383: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1465 - accuracy: 0.9792 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1925 - accuracy: 0.9688\n",
      "Epoch 384: val_loss improved from 0.11160 to 0.11160, saving model to ./model\\iris-384-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1866 - accuracy: 0.9792 - val_loss: 0.1116 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1100 - accuracy: 1.0000\n",
      "Epoch 385: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1470 - accuracy: 0.9896 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "Epoch 386: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1542 - accuracy: 0.9792 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
      "Epoch 387/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
      "Epoch 387: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1391 - accuracy: 0.9896 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1829 - accuracy: 0.9688\n",
      "Epoch 388: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1464 - accuracy: 0.9792 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1249 - accuracy: 1.0000\n",
      "Epoch 389: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1871 - accuracy: 0.9792 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1675 - accuracy: 0.9688\n",
      "Epoch 390: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1419 - accuracy: 0.9896 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1038 - accuracy: 1.0000\n",
      "Epoch 391: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1605 - accuracy: 0.9896 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1085 - accuracy: 1.0000\n",
      "Epoch 392: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1532 - accuracy: 0.9896 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1142 - accuracy: 1.0000\n",
      "Epoch 393: val_loss did not improve from 0.11160\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1589 - accuracy: 0.9896 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1282 - accuracy: 1.0000\n",
      "Epoch 394: val_loss improved from 0.11160 to 0.10951, saving model to ./model\\iris-394-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1471 - accuracy: 0.9896 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1293 - accuracy: 1.0000\n",
      "Epoch 395: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1426 - accuracy: 0.9896 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1047 - accuracy: 1.0000\n",
      "Epoch 396: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1547 - accuracy: 0.9896 - val_loss: 0.1281 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1317 - accuracy: 1.0000\n",
      "Epoch 397: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1490 - accuracy: 0.9792 - val_loss: 0.1236 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1119 - accuracy: 1.0000\n",
      "Epoch 398: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1335 - accuracy: 0.9896 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1927 - accuracy: 0.9688\n",
      "Epoch 399: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1346 - accuracy: 0.9896 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1901 - accuracy: 0.9688\n",
      "Epoch 400: val_loss did not improve from 0.10951\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1469 - accuracy: 0.9896 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1133 - accuracy: 1.0000\n",
      "Epoch 401: val_loss improved from 0.10951 to 0.10508, saving model to ./model\\iris-401-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1207 - accuracy: 0.9896 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2630 - accuracy: 0.9688\n",
      "Epoch 402: val_loss did not improve from 0.10508\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1603 - accuracy: 0.9896 - val_loss: 0.1077 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1050 - accuracy: 1.0000\n",
      "Epoch 403: val_loss improved from 0.10508 to 0.10440, saving model to ./model\\iris-403-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1506 - accuracy: 0.9792 - val_loss: 0.1044 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1659 - accuracy: 0.9688\n",
      "Epoch 404: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1339 - accuracy: 0.9896 - val_loss: 0.1098 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1511 - accuracy: 1.0000\n",
      "Epoch 405: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1531 - accuracy: 0.9896 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0988 - accuracy: 1.0000\n",
      "Epoch 406: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1164 - accuracy: 0.9896 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 407: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1273 - accuracy: 0.9896 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9688\n",
      "Epoch 408: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1607 - accuracy: 0.9896 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2192 - accuracy: 0.9688\n",
      "Epoch 409: val_loss did not improve from 0.10440\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1517 - accuracy: 0.9792 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 410: val_loss improved from 0.10440 to 0.10184, saving model to ./model\\iris-410-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1265 - accuracy: 0.9896 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1535 - accuracy: 0.9688\n",
      "Epoch 411: val_loss did not improve from 0.10184\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1447 - accuracy: 0.9792 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 412: val_loss did not improve from 0.10184\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1458 - accuracy: 0.9792 - val_loss: 0.1248 - val_accuracy: 0.9583\n",
      "Epoch 413/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2445 - accuracy: 0.9688\n",
      "Epoch 413: val_loss did not improve from 0.10184\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1485 - accuracy: 0.9896 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1016 - accuracy: 1.0000\n",
      "Epoch 414: val_loss improved from 0.10184 to 0.10021, saving model to ./model\\iris-414-val1.0000.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1236 - accuracy: 0.9896 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1877 - accuracy: 0.9688\n",
      "Epoch 415: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1530 - accuracy: 0.9896 - val_loss: 0.1062 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1547 - accuracy: 1.0000\n",
      "Epoch 416: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1409 - accuracy: 0.9896 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1086 - accuracy: 1.0000\n",
      "Epoch 417: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1310 - accuracy: 0.9896 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0985 - accuracy: 1.0000\n",
      "Epoch 418: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1563 - accuracy: 0.9688 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1077 - accuracy: 1.0000\n",
      "Epoch 419: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1343 - accuracy: 0.9896 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 420: val_loss did not improve from 0.10021\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1459 - accuracy: 0.9792 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2305 - accuracy: 0.9688\n",
      "Epoch 421: val_loss improved from 0.10021 to 0.09925, saving model to ./model\\iris-421-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1424 - accuracy: 0.9896 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1150 - accuracy: 1.0000\n",
      "Epoch 422: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1553 - accuracy: 0.9792 - val_loss: 0.1000 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0729 - accuracy: 1.0000\n",
      "Epoch 423: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1273 - accuracy: 0.9896 - val_loss: 0.1127 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1621 - accuracy: 0.9688\n",
      "Epoch 424: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1278 - accuracy: 0.9896 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1476 - accuracy: 1.0000\n",
      "Epoch 425: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1413 - accuracy: 0.9896 - val_loss: 0.1086 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2166 - accuracy: 0.9688\n",
      "Epoch 426: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1381 - accuracy: 0.9896 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 427: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1208 - accuracy: 0.9896 - val_loss: 0.1013 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1915 - accuracy: 0.9688\n",
      "Epoch 428: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1319 - accuracy: 0.9896 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9688\n",
      "Epoch 429: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1236 - accuracy: 0.9896 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1140 - accuracy: 1.0000\n",
      "Epoch 430: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1281 - accuracy: 0.9896 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1754 - accuracy: 0.9688\n",
      "Epoch 431: val_loss did not improve from 0.09925\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1309 - accuracy: 0.9896 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1003 - accuracy: 1.0000\n",
      "Epoch 432: val_loss improved from 0.09925 to 0.09212, saving model to ./model\\iris-432-val1.0000.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1318 - accuracy: 0.9896 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 433: val_loss did not improve from 0.09212\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1783 - accuracy: 0.9792 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
      "Epoch 434: val_loss did not improve from 0.09212\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1483 - accuracy: 0.9792 - val_loss: 0.1328 - val_accuracy: 0.9583\n",
      "Epoch 435/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2425 - accuracy: 0.9375\n",
      "Epoch 435: val_loss did not improve from 0.09212\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1598 - accuracy: 0.9688 - val_loss: 0.1065 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1964 - accuracy: 0.9688\n",
      "Epoch 436: val_loss improved from 0.09212 to 0.09121, saving model to ./model\\iris-436-val1.0000.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1584 - accuracy: 0.9688 - val_loss: 0.0912 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0905 - accuracy: 1.0000\n",
      "Epoch 437: val_loss improved from 0.09121 to 0.08906, saving model to ./model\\iris-437-val1.0000.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1906 - accuracy: 0.9688 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0816 - accuracy: 1.0000\n",
      "Epoch 438: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1538 - accuracy: 0.9896 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 439: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1376 - accuracy: 0.9792 - val_loss: 0.1472 - val_accuracy: 0.9583\n",
      "Epoch 440/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3062 - accuracy: 0.9062\n",
      "Epoch 440: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1643 - accuracy: 0.9688 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1889 - accuracy: 0.9688\n",
      "Epoch 441: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1633 - accuracy: 0.9792 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0944 - accuracy: 1.0000\n",
      "Epoch 442: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1369 - accuracy: 0.9896 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1071 - accuracy: 1.0000\n",
      "Epoch 443: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1244 - accuracy: 0.9896 - val_loss: 0.1214 - val_accuracy: 0.9583\n",
      "Epoch 444/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
      "Epoch 444: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1392 - accuracy: 0.9792 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2145 - accuracy: 0.9688\n",
      "Epoch 445: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1493 - accuracy: 0.9896 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1811 - accuracy: 0.9688\n",
      "Epoch 446: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1495 - accuracy: 0.9896 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2402 - accuracy: 0.9688\n",
      "Epoch 447: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1372 - accuracy: 0.9896 - val_loss: 0.1211 - val_accuracy: 0.9583\n",
      "Epoch 448/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1581 - accuracy: 0.9688\n",
      "Epoch 448: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1528 - accuracy: 0.9792 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2036 - accuracy: 0.9688\n",
      "Epoch 449: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1402 - accuracy: 0.9896 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0872 - accuracy: 1.0000\n",
      "Epoch 450: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1311 - accuracy: 0.9792 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1211 - accuracy: 0.9688\n",
      "Epoch 451: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1378 - accuracy: 0.9792 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1235 - accuracy: 1.0000\n",
      "Epoch 452: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1493 - accuracy: 0.9896 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1332 - accuracy: 1.0000\n",
      "Epoch 453: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1272 - accuracy: 0.9896 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1728 - accuracy: 0.9688\n",
      "Epoch 454: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1457 - accuracy: 0.9896 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2604 - accuracy: 0.9688\n",
      "Epoch 455: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1475 - accuracy: 0.9896 - val_loss: 0.1009 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2201 - accuracy: 0.9688\n",
      "Epoch 456: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1357 - accuracy: 0.9896 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1986 - accuracy: 0.9688\n",
      "Epoch 457: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1230 - accuracy: 0.9896 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1869 - accuracy: 0.9688\n",
      "Epoch 458: val_loss did not improve from 0.08906\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1331 - accuracy: 0.9896 - val_loss: 0.0997 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1419 - accuracy: 0.9688\n",
      "Epoch 459: val_loss improved from 0.08906 to 0.08861, saving model to ./model\\iris-459-val1.0000.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1386 - accuracy: 0.9792 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000\n",
      "Epoch 460: val_loss did not improve from 0.08861\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1235 - accuracy: 0.9792 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0842 - accuracy: 1.0000\n",
      "Epoch 461: val_loss did not improve from 0.08861\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1275 - accuracy: 0.9792 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1770 - accuracy: 0.9688\n",
      "Epoch 462: val_loss did not improve from 0.08861\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1230 - accuracy: 0.9792 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1350 - accuracy: 0.9688\n",
      "Epoch 463: val_loss improved from 0.08861 to 0.08659, saving model to ./model\\iris-463-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1373 - accuracy: 0.9792 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1251 - accuracy: 1.0000\n",
      "Epoch 464: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1506 - accuracy: 0.9792 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1843 - accuracy: 0.9688\n",
      "Epoch 465: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1245 - accuracy: 0.9896 - val_loss: 0.1225 - val_accuracy: 0.9583\n",
      "Epoch 466/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2734 - accuracy: 0.9062\n",
      "Epoch 466: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1663 - accuracy: 0.9688 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 467: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1166 - accuracy: 0.9896 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000\n",
      "Epoch 468: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1391 - accuracy: 0.9896 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2523 - accuracy: 0.9688\n",
      "Epoch 469: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1621 - accuracy: 0.9896 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1731 - accuracy: 0.9688\n",
      "Epoch 470: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1312 - accuracy: 0.9896 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1759 - accuracy: 0.9375\n",
      "Epoch 471: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1711 - accuracy: 0.9688 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 472: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1312 - accuracy: 0.9792 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 473: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1320 - accuracy: 0.9896 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 474: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1401 - accuracy: 0.9792 - val_loss: 0.1032 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0886 - accuracy: 1.0000\n",
      "Epoch 475: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1304 - accuracy: 0.9896 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 476: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1128 - accuracy: 0.9896 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0814 - accuracy: 1.0000\n",
      "Epoch 477: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9896 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1760 - accuracy: 0.9688\n",
      "Epoch 478: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1287 - accuracy: 0.9896 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1697 - accuracy: 0.9375\n",
      "Epoch 479: val_loss did not improve from 0.08659\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1238 - accuracy: 0.9792 - val_loss: 0.0974 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 480: val_loss improved from 0.08659 to 0.08172, saving model to ./model\\iris-480-val1.0000.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1271 - accuracy: 0.9896 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 481: val_loss did not improve from 0.08172\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1252 - accuracy: 0.9896 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 482: val_loss did not improve from 0.08172\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1620 - accuracy: 0.9792 - val_loss: 0.1108 - val_accuracy: 0.9583\n",
      "Epoch 483/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1685 - accuracy: 0.9688\n",
      "Epoch 483: val_loss did not improve from 0.08172\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1397 - accuracy: 0.9792 - val_loss: 0.1434 - val_accuracy: 0.9583\n",
      "Epoch 484/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 484: val_loss did not improve from 0.08172\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1336 - accuracy: 0.9792 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 485: val_loss improved from 0.08172 to 0.08131, saving model to ./model\\iris-485-val1.0000.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1303 - accuracy: 0.9896 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9688\n",
      "Epoch 486: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1266 - accuracy: 0.9896 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0917 - accuracy: 1.0000\n",
      "Epoch 487: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1334 - accuracy: 0.9896 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 488: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1179 - accuracy: 0.9896 - val_loss: 0.1106 - val_accuracy: 0.9583\n",
      "Epoch 489/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 489: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1419 - accuracy: 0.9896 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0887 - accuracy: 1.0000\n",
      "Epoch 490: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1382 - accuracy: 0.9896 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9688\n",
      "Epoch 491: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1184 - accuracy: 0.9896 - val_loss: 0.0926 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 492: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0937 - accuracy: 0.9896 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1140 - accuracy: 0.9688\n",
      "Epoch 493: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1062 - accuracy: 0.9896 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0922 - accuracy: 1.0000\n",
      "Epoch 494: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1269 - accuracy: 0.9792 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2177 - accuracy: 0.9688\n",
      "Epoch 495: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1289 - accuracy: 0.9896 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9688\n",
      "Epoch 496: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1245 - accuracy: 0.9896 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9688\n",
      "Epoch 497: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1276 - accuracy: 0.9896 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0872 - accuracy: 1.0000\n",
      "Epoch 498: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1229 - accuracy: 0.9896 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 499: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1243 - accuracy: 0.9896 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1302 - accuracy: 0.9688\n",
      "Epoch 500: val_loss did not improve from 0.08131\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1099 - accuracy: 0.9896 - val_loss: 0.0932 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 4. 학습 : epoch마다 val_accuracy(val_loss, accuracy, loss) 값이 좋을 때 모델을 자동 저장 콜백 추가\n",
    "    # 모델을 저장할 경로 : ./model/iris-100-val0.6521.h5\n",
    "import os\n",
    "model_save_folder = './model/'\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.mkdir(model_save_folder) # model_save_folder가 없으면 폴더 생성\n",
    "\n",
    "# 조기종료 콜백\n",
    "earlyStopping = EarlyStopping(patience=40) # monitor='val_loss' 기본값\n",
    "# 모델 자동 저장 콜백\n",
    "file = model_save_folder + 'iris-{epoch:03d}-val{val_accuracy:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=file,\n",
    "                             monitor='val_loss', # 모니터링 지표\n",
    "                             save_best_only=True, # 지표가 개선된 경우만 저장. False면 매번저장\n",
    "                             mode='auto', # 값이 클수록 저장. 'min'은 값이 작을수록 저장. auto\n",
    "                             verbose = 1 # 저장 여부 로그 출력 (0:출력안함)\n",
    "                            )\n",
    "\n",
    "hist = model.fit(X_train, Y_train,\n",
    "                 epochs=500,\n",
    "                 validation_split=.2,\n",
    "                 callbacks=[checkpoint, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbb62a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:31:31.038858Z",
     "start_time": "2024-12-19T08:31:30.780090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots(figsize=(10,5))\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'y', label='validation loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax = loss_ax.twinx()\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='validation accuracy')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(bbox_to_anchor=(1.1, 1), loc=2, borderaxespad=0.)\n",
    "acc_ax.legend(bbox_to_anchor=(1.1, .85), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dc6916f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:31:34.245518Z",
     "start_time": "2024-12-19T08:31:34.171715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1835 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1834961324930191, 0.9333333373069763]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d839282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:31:35.026843Z",
     "start_time": "2024-12-19T08:31:34.923818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 0, 2,\n",
       "        1, 0, 0, 1, 2, 1, 0, 1], dtype=int64),\n",
       " array([2, 2, 1, 1, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 0, 2, 0, 0, 2,\n",
       "        1, 0, 0, 1, 2, 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차표\n",
    "real = Y_test.argmax(axis=1)\n",
    "pred = np.argmax(model.predict(X_test), axis=1)\n",
    "real, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2679c357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:31:35.760496Z",
     "start_time": "2024-12-19T08:31:35.740548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict     setosa  versicolor  virginica\n",
       "real                                     \n",
       "setosa          10           0          0\n",
       "versicolor       0           8          2\n",
       "virginica        0           0         10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctab = pd.crosstab(real, pred)\n",
    "ctab.columns = iris['species'][::50]\n",
    "ctab.columns.name = 'predict'\n",
    "ctab.index = iris['species'][::50]\n",
    "ctab.index.name = 'real'\n",
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bdd756b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:34:22.076927Z",
     "start_time": "2024-12-19T08:34:21.787745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5188 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5188468098640442, 0.9666666388511658]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델 중 성능이 제일 좋아 보이는 것 load\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('model/iris1.h5')\n",
    "model2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37d03a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:34:23.351263Z",
     "start_time": "2024-12-19T08:34:23.244177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict     setosa  versicolor  virginica\n",
       "real                                     \n",
       "setosa          10           0          0\n",
       "versicolor       0           9          1\n",
       "virginica        0           0         10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델의 교차표\n",
    "real = Y_test.argmax(axis=1)\n",
    "pred = np.argmax(model2.predict(X_test), axis=1)\n",
    "ctab = pd.crosstab(real, pred)\n",
    "ctab.columns = iris['species'][::50]\n",
    "ctab.columns.name = 'predict'\n",
    "ctab.index = iris['species'][::50]\n",
    "ctab.index.name = 'real'\n",
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b5cf0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:36:47.866784Z",
     "start_time": "2024-12-19T08:36:47.855810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width     species\n",
       "50           7.0          3.2           4.7          1.4  versicolor\n",
       "51           6.4          3.2           4.5          1.5  versicolor"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용하기 (예측하기)\n",
    "iris[50:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a935f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T08:37:02.490146Z",
     "start_time": "2024-12-19T08:37:02.428198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06150612, 0.48908028, 0.44941363]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(np.array([[6.4, 3.2, 4.5, 1.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a38ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

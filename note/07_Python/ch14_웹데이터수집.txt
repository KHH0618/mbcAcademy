1. 웹 데이터 수집 종류:  
   - 뉴스 기사 크롤링: RSS와 XML 형식으로 데이터 수집  
   - SNS 데이터 크롤링: 텍스트 형식으로 트위터, 댓글 등 데이터 수집  
   - 웹 페이지 크롤링: HTML 형식으로 원하는 정보 추출  
   - 공공 데이터 수집: Open API를 이용하여 CSV나 JSON 형식의 정형 데이터를 수집  

2. 웹 크롤링의 한계:  
   - 크롤러 제한 규칙, HTTP 헤더 제한, 동적 웹사이트, 캡챠, 로그인 필요, IP 차단, 법적 금지 등이 주요 한계로 작용  

3. Beautiful Soup과 파서:  
   - HTML과 XML 문서를 파싱하고 필요한 데이터를 추출하는 라이브러리  
   - 다양한 파서 지원 (html.parser, lxml 등)  
   - CSS 선택자를 사용해 원하는 요소를 쉽게 찾을 수 있음 (select, select_one)  

4. requests 모듈:  
   - HTTP 요청과 응답을 처리하는 라이브러리  
   - GET, POST 요청을 통해 데이터를 가져오고 상태 코드, 헤더, 본문(Content) 등 정보 확인 가능  
   - JSON 데이터 처리와 API 호출에도 유용  

5. Selenium을 이용한 웹 데이터 수집:  
   - 브라우저 자동화를 통해 동적 웹사이트에서 데이터 수집  
   - 웹드라이버 설정, 브라우저 실행, 이벤트 처리, 데이터 추출 과정을 포함  

6. 활용 시 주의사항:  
   - 크롤링 대상 사이트의 이용 약관 및 법적 규제를 준수해야 하며, 과도한 요청으로 서버에 부담을 주지 않도록 해야 함.